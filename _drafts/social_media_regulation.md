---
layout: post
title: "Social Media Regulation: A Proposal"
date: 2026-01-28
tags: [social media, psychology, politics]
---

Fine - you drove me to it. Last time I posted about this I hit the number 1
spot on Hacker News and was (rightly) skewered for not providing a solution -
just listing a bunch of problems. This time...I have answers. <!--more-->

Before I get onto them, I'd like to thank my colleagues with whom I holidayed
(see my previous post) and ultimately sharpened these ideas. So, let's get
started - how do we set about banning (or not) social media?

## Guiding Principles

I have absolutely **zero** interest in telling teenagers how they can talk to
each other. Every generation wishes they could insert themselves into the
conversations of their teenagers and stop their minds being warped. Every
generation is wrong to do so. Let's leave the kids alone to talk.

That means that I'm only going to be regulating ***algorithmic feeds***. I
don't have evidence that they're more harmful that the combination of
smartphone cameras and Instagram, or talking with your friends in an
unregulated way...but they're the bit I'm most scared of so I'm starting there.

I have **very little** interest in uniquely targeting teenagers with
regulations until evidence says that they are uniquely likely to be harmed by
social media.

I strongly believe that any approach must be:

1. **Gradual** - I can't abide the thought of dropping a 16/18 year old with no
   experience of social media whatsoever into the bull pen that is a
state-of-the-art algorithmic feed.
2. **Practical** - I can't abide calls to "regulate the algorithms" without any
   degree of specificity. Think like you work at a tech company (I do) and make
concrete suggestions that could actually be implemented.

Right, with that out of the way, let's begin with 8 year olds.

## Young Children

The simple answer would be to ban algorithmic feeds for young children, but
that doesn't sound practical or gradual. Let's start by defanging them a little
bit.

I state that for children under the age of 11, any 'feed' of content can
only use geography, language, time and age as features. No personalisation. No more
granular features. Any feed will ultimately have to wring whatever signal it
can out of the most popular content for your geography, language and age.

I continue to believe that messaging (whether through texts, WhatsApp,
Messenger, TikTok etc.) should be unencumbered by specific legislation.

## Older Children

Given how I've stated my opening gambit for younger children, and the
principles I've laid out, I think you can tell what I'm going to say for older
children. 

At some point, I'd like tech companies to be able to introduce gender as a
feature. As any data scientist will tell you, this is one of the more important
features for generating content-based predictions - exactly when we should be
able to recommend boys wrestling content and girls murder content is an open
question.

I'd also like to introduce stated choice (if I select certain topics, I can get
popular items within those topics), local geography (topics relevant to my
town/city), and gradually...any other demographic information a tech company
has access to and believes it can use.

Ultimately, as a child gets older, I'd like to make their recommendations better and
better. Isn't that making their algorithmic feeds stickier and stickier,
pontentially leading to more and more harm? Maybe.

But as soon as they hit $AGE_OF_CONSENT$ they're going to be hit with the
full-force of personalised algorthimically curated feeds that are designed to
circumvent the decision-making part of your brain and go straight to the automatic
response system. All we're hoping to do is to make that a gradual process and
now...what happens when you get there?

## Adults

Last time I argued (by symmetry, and possibly poorly) that you shouldn't ban social media for children without
regulating the experience for adults. I drew analogies to the gambling
industries and I'd like to do so again.

Gambling offers repeated reminders that you should be having fun, it allows you
to set time and monetary limits, and it shows you how much you have spent.

Using the age old maxim that time = money, does the fact that algorithmic feeds
spend your time rather than your money absolve them of those responsibilities?
Currently, no. But I'd argue that algorithmic feeds should come with exactly
the same set of controls.

- "You have spent 22 hours this week scrolling"
- "You only have 15 minutes left on your 4 hour daily limit"
- "Would you like to set a time limit?"
- "Your usage is up by 17% this week compared to last week. Would you like to
  take a break?"

None of that sounds especially onerus. All of that could be comfortably
implemented in relatively little time by companies operating algorithmic feeds.
The only reason that they haven't is that they haven't been required to.

Secondly, I'd love to require content to be highlighted if it was "generated
algorithmically". Let's be practical and specify what that means. That means
that if the content is being served to a person because of a personalised
model, it should be highlighted.

Right now, that'd be all content on most platforms. But it wouldn't have to be.
You could have a pool of 'friend-generated' content, a pool of
'popular-given-demographic' content and a pool of 'personalised content'. At a
basic level, we could allow fixed proportions or deterministic rules choosing
from which pools content would be drawn. I think I could be persuaded to
actually allow a personalised model to pull content from each of these pools.
However, I think they'd have to pull from the top of the lists - and the lists
themselves must be ordered in a non-personalised (or at least in an
explainable, deterministic, non-dependent-on-behaviour sort of way).

## Downsides

I'm making the experience of using algorithmic feeds worse for everybody (in
the short-term, at least). Rather than seeing content that works perfectly for
you, you're seeing the average content that works for everybody. 

I'm killing a bunch of businesses - and potentially communities. Anybody who
requires finding their niche is going to have a greatly reduced ability to find
them.

I don't really have any concrete proof that algorithmic feeds are (especially)
bad for teens and yet they'll be the ones to bear the brunt of this regulation.

Children will probably still spend hours on end on 'social media', and will
struggle with all the things that children and teenagers have struggled with
for years (belonging, identity, group dynamics).

## Conclusion

I've propsed an implementable and impactful set of regulations for social
media. It isn't a "ban on social media for under 16s" and will still let them
speak to their friends without state intervention. It won't have the side
effect of dropping their untrained minds onto the algorithmic highway at 16. It
will gradually introduce them to the digital world in a contrallable way. It
comes with gambling-like regulation for adult social media use.

What do you think?
